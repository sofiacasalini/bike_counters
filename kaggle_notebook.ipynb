{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import external_data.external_data_functions as ext\n",
    "import my_utils\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression\n",
    "from skrub import TableVectorizer\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = my_utils.get_train_data()\n",
    "X = ext._merge_external_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = my_utils.train_test_split_temporal(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_encoder = FunctionTransformer(my_utils._encode_dates)\n",
    "cyclic_features = FunctionTransformer(my_utils.create_time_features)\n",
    "categorical_encoder = OrdinalEncoder()\n",
    "categorical_cols = [\"counter_id\", \"site_id\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "regressor = ExtraTreesRegressor()\n",
    "\n",
    "\n",
    "\"\"\"xgb.XGBRegressor(max_depth = 7, \n",
    "                             colsample_bytree = 0.8, \n",
    "                             learning_rate = 0.3, \n",
    "                             min_child_weight = 5, \n",
    "                             subsample = 0.6)\"\"\"\n",
    "\n",
    "# ExtraTreesRegressor() --> best score\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"date_encoding\", date_encoder),\n",
    "        (\"cyclic_features\", cyclic_features),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", regressor),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X, y)\n",
    "# pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Train set, RMSE={mean_squared_error(y_train, pipe.predict(X_train), squared=False):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Valid set, RMSE={mean_squared_error(y_valid, pipe.predict(X_valid), squared=False):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(pipe, \"trained_pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "\n",
    "param_grid = {\n",
    "    \"regressor__max_depth\": [5, 6, 7],\n",
    "    \"regressor__min_child_weight\": [1, 3, 5],\n",
    "    \"regressor__subsample\": [0.6, 0.8, 1.0],\n",
    "    \"regressor__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"regressor__learning_rate\": [0.01, 0.1, 0.3],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    # param_distributions=param_grid, #for RandomizedSearch\n",
    "    # n_iter = 50, #For RandomizedSearch\n",
    "    scoring=\"neg_mean_squared_error\",  # Change to appropriate scoring metric for regression\n",
    "    cv=my_utils.get_cv(X, y),  # Number of cross-validation folds\n",
    "    verbose=4,  # To display progress\n",
    "    n_jobs=-1,  # Use all available processors\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Get the best pipeline\n",
    "best_pipeline = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=6)\n",
    "\n",
    "# When using a scorer in scikit-learn it always needs to be better when smaller, hence the minus sign.\n",
    "scores = cross_val_score(\n",
    "    pipe, X_train, y_train, cv=cv, scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "print(\"RMSE: \", scores)\n",
    "print(f\"RMSE (all folds): {-scores.mean():.3} Â± {(-scores).std():.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_parquet(Path(\"data\") / \"final_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ext._merge_external_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the trained pipeline\n",
    "loaded_model = load(\"trained_pipeline.joblib\")  # here loaded with ExtraTreesRegressor()\n",
    "\n",
    "predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"Id\": X_test.reset_index().index,  # Use appropriate index or ID column from the test data\n",
    "        \"log_bike_count\": predictions,\n",
    "    }\n",
    ")\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
